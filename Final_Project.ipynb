{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import tensorflow.contrib.learn as tflearn\n",
    "import tensorflow.contrib.layers as tflayers\n",
    "import tensorflow.contrib.metrics as metrics\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, roc_auc_score, accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from scipy.stats import norm\n",
    "\n",
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227846, 29) (227846, 1) (56961, 29) (56961, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "394"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Original Data => Original test & Original Train using Striatified for saving data structure\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "x = df.drop(['Class','Time'], axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "for train_index, test_index in skf.split(x, y):\n",
    "    x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "x_train = tf.keras.utils.normalize(x_train.values, axis = 1, order = 1) \n",
    "x_test = tf.keras.utils.normalize(x_test.values, axis = 1, order = 1) \n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "np.sum(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "epochs = 2000\n",
    "batch_size = 100\n",
    "lr = 1e-3\n",
    "hidden_layers1 = 20\n",
    "hidden_layers2 = 15\n",
    "\n",
    "# placeholders\n",
    "X = tf.placeholder(tf.float32, (None,29), name=\"X\")\n",
    "Y = tf.placeholder(tf.float32, (None,1), name=\"Y\")\n",
    "\n",
    "# initializers\n",
    "init_b = tf.keras.initializers.constant(0.0)\n",
    "init_w = tf.keras.initializers.VarianceScaling(mode='fan_avg')\n",
    "\n",
    "# layer 1\n",
    "b1 = tf.get_variable('b1',(15,), tf.float32, init_b)\n",
    "w1 = tf.get_variable('w1',(29,15), tf.float32, init_w)\n",
    "\n",
    "# layer 2\n",
    "b2 = tf.get_variable('b2',(10,), tf.float32, init_b)\n",
    "w2 = tf.get_variable('w2',(15,10), tf.float32, init_w)\n",
    "\n",
    "# activation\n",
    "X1 = tf.nn.leaky_relu(X @ w1 + b1)\n",
    "logits = X1 @ w2 + b2\n",
    "\n",
    "y_pred = tf.cast(tf.argmax(logits, axis=1), tf.int32, name='y_pred_cls')\n",
    "entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits=logits)\n",
    "loss = tf.reduce_mean(entropy)\n",
    "\n",
    "# optimizer\n",
    "train = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(x, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(x))\n",
    "    n_batches = len(x) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        yield x[batch_idx], y[batch_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 0/2000 "
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' objects are mutable, thus they cannot be hashed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e6bf3f4d7c1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch {}/{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mshuffle_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mloss_run\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_run\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mloss_trace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_run\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1884\u001b[0m         raise TypeError(\n\u001b[0;32m   1885\u001b[0m             \u001b[1;34m\"{0!r} objects are mutable, thus they cannot be\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1886\u001b[1;33m             \u001b[1;34m\" hashed\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1887\u001b[0m         )\n\u001b[0;32m   1888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DataFrame' objects are mutable, thus they cannot be hashed"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    #saver.restore(sess, 'save/nn.ckpt')\n",
    "    \n",
    "    loss_trace = []\n",
    "    accuracy_trace = []\n",
    "\n",
    "    for i in range(epochs):\n",
    "        print()\n",
    "        print('epoch {}/{}'.format(i, epochs), end=' ')\n",
    "        for x_batch, y_batch in shuffle_batch(x_train, y_train, batch_size):\n",
    "            feed_dict = {x: x_batch, y: y_batch}\n",
    "            loss_run, accuracy_run, _ = sess.run([loss, accuracy, train], feed_dict=feed_dict)\n",
    "            loss_trace.append(loss_run)\n",
    "            accuracy_trace.append(accuracy_run)\n",
    "\n",
    "    feed_dict = {x: x_test, y: y_test}\n",
    "    accuracy_run, y_test_pred = sess.run([accuracy, y_pred], feed_dict=feed_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
